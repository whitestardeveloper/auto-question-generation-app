#Â ollama models

### v1 models
MODELS=("gemma2" "aya-expanse" "mistral-nemo" "llama3.1" "qwen2.5", "mistral")


### v2 models
MODELS=("gemma2" "aya-expanse" "mistral-nemo" "llama3.1" "qwen2.5", "mistral")

    - ollama run gemma2:27b    (27GB)
    - ollama run aya-expanse:32b    (20GB)
    - ollama run llama3.1:70b     (40GB)
    - ollama run qwen2.5:32b      (20GB)
    - ollama run mistral-small   (13GB)

Total 120 GB